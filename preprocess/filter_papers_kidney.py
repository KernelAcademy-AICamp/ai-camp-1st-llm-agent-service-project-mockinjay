#!/usr/bin/env python3
"""
Papers Dataset Kidney Filtering Script
í•„í„°ë§ ê¸°ì¤€:
1. í‚¤ì›Œë“œ ë§¤ì¹­: title, abstract, keywordsì—ì„œ ì‹ ì¥ ê´€ë ¨ ìš©ì–´ ê²€ìƒ‰
2. Claudeì˜ íŒë‹¨: í‚¤ì›Œë“œê°€ ì—†ê±°ë‚˜ ì• ë§¤í•œ ê²½ìš° ë¬¸ë§¥ ì´í•´
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple

# íŒŒì¼ ê²½ë¡œ
BASE_DIR = Path(__file__).parent.parent
TERMINOLOGY_FILE = BASE_DIR / "data/preprocess/kidney_terminology.json"
INPUT_FILE = BASE_DIR / "data/preprocess/unified_output/paper_dataset_enriched_s2_checkpoint_4850.jsonl"
OUTPUT_FILE = BASE_DIR / "data/preprocess/kidney_filtered/papers_kidney.jsonl"
PROGRESS_FILE = BASE_DIR / "data/preprocess/kidney_filtered/FILTERING_PROGRESS.md"

class KidneyTerminologyMatcher:
    """ì‹ ì¥ ìš©ì–´ ë§¤ì¹­ í´ë˜ìŠ¤"""

    def __init__(self, terminology_file: Path):
        """ìš©ì–´ì§‘ ë¡œë“œ"""
        with open(terminology_file, 'r', encoding='utf-8') as f:
            self.terminology = json.load(f)

        # í•µì‹¬ ì‹ ì¥ ìš©ì–´ (ë°˜ë“œì‹œ í•˜ë‚˜ëŠ” í¬í•¨ë˜ì–´ì•¼ í•¨)
        self.core_kidney_terms = {
            'kidney', 'kidneys', 'renal', 'nephro', 'nephrology', 'nephrologist',
            'nephron', 'glomerulus', 'glomeruli', 'glomerular',
            'ì‹ ì¥', 'ì½©íŒ¥', 'ì‚¬êµ¬ì²´', 'ì‹ ì¥í•™'
        }

        # ê³ íŠ¹ì´ë„ ì‹ ì¥ ìš©ì–´ (ì´ê²ƒë§Œ ìˆì–´ë„ ì‹ ì¥ ê´€ë ¨ìœ¼ë¡œ íŒë‹¨)
        self.high_specificity_terms = {
            # ì˜ì–´
            'dialysis', 'hemodialysis', 'haemodialysis', 'peritoneal dialysis',
            'nephrotic syndrome', 'nephritic syndrome', 'glomerulonephritis',
            'nephropathy', 'nephritis', 'nephrosis',
            'kidney transplant', 'kidney transplantation', 'renal transplant', 'renal transplantation',
            'acute kidney injury', 'chronic kidney disease', 'end-stage renal disease', 'renal failure',
            'proteinuria', 'albuminuria', 'hematuria',
            'IgA nephropathy', 'membranous nephropathy', 'focal segmental glomerulosclerosis',
            'diabetic nephropathy', 'diabetic kidney disease',
            'polycystic kidney disease', 'kidney stone', 'nephrolithiasis',
            'pyelonephritis', 'interstitial nephritis',
            'renal artery stenosis', 'hydronephrosis',
            'renal cell carcinoma', 'kidney cancer',
            # ì•½ì–´
            'CKD', 'ESRD', 'ESKD', 'AKI', 'ARF', 'FSGS', 'CAPD', 'APD', 'CRRT',
            'PKD', 'ADPKD', 'RCC', 'GFR', 'eGFR',
            # í•œêµ­ì–´
            'íˆ¬ì„', 'í˜ˆì•¡íˆ¬ì„', 'ë³µë§‰íˆ¬ì„', 'ì‹ ì¦í›„êµ°', 'ì‹ ì—¼ì¦í›„êµ°', 'ì‚¬êµ¬ì²´ì‹ ì—¼',
            'ì‹ ë³‘ì¦', 'ì‹ ì—¼', 'ì‹ ì´ì‹', 'ì‹ ì¥ì´ì‹', 'ì½©íŒ¥ì´ì‹',
            'ê¸‰ì„±ì‹ ì†ìƒ', 'ë§Œì„±ì½©íŒ¥ë³‘', 'ë§ê¸°ì‹ ë¶€ì „', 'ì‹ ë¶€ì „',
            'ë‹¨ë°±ë‡¨', 'ì•Œë¶€ë¯¼ë‡¨', 'í˜ˆë‡¨',
            'IgAì‹ ë³‘ì¦', 'ë§‰ì„±ì‹ ë³‘ì¦', 'êµ­ì†Œë¶„ì ˆì‚¬êµ¬ì²´ê²½í™”ì¦',
            'ë‹¹ë‡¨ë³‘ì„±ì‹ ë³‘ì¦', 'ë‹¹ë‡¨ì½©íŒ¥ë³‘',
            'ë‹¤ë‚­ì½©íŒ¥ë³‘', 'ì‹ ê²°ì„', 'ì‹ ìš°ì‹ ì—¼', 'ê°„ì§ˆì‹ ì—¼',
            'ì‹ ë™ë§¥í˜‘ì°©', 'ìˆ˜ì‹ ì¦', 'ì‹ ì„¸í¬ì•”', 'ì½©íŒ¥ì•”'
        }

        # ì¼ë°˜ ìš©ì–´ (í•µì‹¬ ìš©ì–´ì™€ í•¨ê»˜ ìˆì–´ì•¼ ì˜ë¯¸ ìˆìŒ)
        self.general_terms = {
            'diabetes', 'diabetic', 'hypertension', 'cardiovascular',
            'anemia', 'edema', 'transplant', 'graft',
            'ë‹¹ë‡¨', 'ë‹¹ë‡¨ë³‘', 'ê³ í˜ˆì••', 'ì‹¬í˜ˆê´€', 'ë¹ˆí˜ˆ', 'ë¶€ì¢…', 'ì´ì‹'
        }

        # ëª¨ë“  ì˜ì–´ ìš©ì–´ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ì„¸íŠ¸ë¡œ ì €ì¥
        self.english_terms = set(term.lower() for term in self.terminology.get('all_english_terms', []))

        # ëª¨ë“  í•œêµ­ì–´ ìš©ì–´ë¥¼ ì„¸íŠ¸ë¡œ ì €ì¥
        self.korean_terms = set(self.terminology.get('all_korean_terms', []))

        # ëª¨ë“  ì•½ì–´ë¥¼ ëŒ€ì†Œë¬¸ì êµ¬ë¶„í•˜ì—¬ ì„¸íŠ¸ë¡œ ì €ì¥
        self.abbreviations = set(self.terminology.get('all_abbreviations', []))

        print(f"âœ… Loaded terminology:")
        print(f"   - Core kidney terms: {len(self.core_kidney_terms)}")
        print(f"   - High specificity terms: {len(self.high_specificity_terms)}")
        print(f"   - General terms: {len(self.general_terms)}")
        print(f"   - Total English terms: {len(self.english_terms)}")
        print(f"   - Total Korean terms: {len(self.korean_terms)}")
        print(f"   - Total Abbreviations: {len(self.abbreviations)}")

    def contains_kidney_term(self, text: str) -> Tuple[bool, List[str]]:
        """
        í…ìŠ¤íŠ¸ì— ì‹ ì¥ ê´€ë ¨ ìš©ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸

        Returns:
            (í¬í•¨ ì—¬ë¶€, ë§¤ì¹­ëœ ìš©ì–´ ë¦¬ìŠ¤íŠ¸)
        """
        if not text:
            return False, []

        matched_terms = []
        text_lower = text.lower()

        # 1. ì˜ì–´ ìš©ì–´ ë§¤ì¹­ (ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­)
        for term in self.english_terms:
            # ë‹¨ì–´ ê²½ê³„ë¥¼ ê³ ë ¤í•œ ì •ê·œì‹ íŒ¨í„´
            # ì˜ˆ: "kidney"ëŠ” ë§¤ì¹­í•˜ì§€ë§Œ "kidneybean"ì€ ë§¤ì¹­í•˜ì§€ ì•ŠìŒ
            pattern = r'\b' + re.escape(term) + r'\b'
            if re.search(pattern, text_lower):
                matched_terms.append(term)

        # 2. í•œêµ­ì–´ ìš©ì–´ ë§¤ì¹­ (ì •í™•í•œ ë§¤ì¹­)
        for term in self.korean_terms:
            if term in text:
                matched_terms.append(term)

        # 3. ì•½ì–´ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„, ë‹¨ì–´ ê²½ê³„ ê³ ë ¤)
        for abbr in self.abbreviations:
            pattern = r'\b' + re.escape(abbr) + r'\b'
            if re.search(pattern, text):
                matched_terms.append(abbr)

        return len(matched_terms) > 0, matched_terms

    def check_paper(self, paper: Dict) -> Tuple[bool, Dict]:
        """
        ë…¼ë¬¸ì´ ì‹ ì¥ ê´€ë ¨ì¸ì§€ í™•ì¸

        í•„í„°ë§ ê¸°ì¤€:
        1. ê³ íŠ¹ì´ë„ ìš©ì–´ê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ í¬í•¨
        2. í•µì‹¬ ì‹ ì¥ ìš©ì–´ê°€ ìˆìœ¼ë©´ í¬í•¨
        3. ì¼ë°˜ ìš©ì–´ë§Œ ìˆìœ¼ë©´ ì œì™¸

        Returns:
            (ì‹ ì¥ ê´€ë ¨ ì—¬ë¶€, ë§¤ì¹­ ì •ë³´ ë”•ì…”ë„ˆë¦¬)
        """
        match_info = {
            'title_match': False,
            'abstract_match': False,
            'keywords_match': False,
            'matched_terms': [],
            'has_core_term': False,
            'has_high_specificity_term': False,
            'has_general_term_only': False
        }

        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•© (title + abstract + keywords)
        title = paper.get('title', '')
        abstract = paper.get('abstract', '')
        keywords = paper.get('metadata', {}).get('keywords', [])
        keywords_text = ' '.join(keywords) if keywords else ''

        full_text = f"{title} {abstract} {keywords_text}"
        full_text_lower = full_text.lower()

        # ë§¤ì¹­ëœ ìš©ì–´ ìˆ˜ì§‘
        matched_terms = []
        has_core = False
        has_high_spec = False
        has_general_only = False

        # 1. ê³ íŠ¹ì´ë„ ìš©ì–´ í™•ì¸
        for term in self.high_specificity_terms:
            term_lower = term.lower() if term.isascii() else term
            if term.isascii():
                # ì˜ì–´: ë‹¨ì–´ ê²½ê³„ ê³ ë ¤
                pattern = r'\b' + re.escape(term_lower) + r'\b'
                if re.search(pattern, full_text_lower):
                    matched_terms.append(term)
                    has_high_spec = True
            else:
                # í•œêµ­ì–´: ì •í™•í•œ ë§¤ì¹­
                if term in full_text:
                    matched_terms.append(term)
                    has_high_spec = True

        # 2. í•µì‹¬ ì‹ ì¥ ìš©ì–´ í™•ì¸
        for term in self.core_kidney_terms:
            term_lower = term.lower() if term.isascii() else term
            if term.isascii():
                pattern = r'\b' + re.escape(term_lower) + r'\b'
                if re.search(pattern, full_text_lower):
                    matched_terms.append(term)
                    has_core = True
            else:
                if term in full_text:
                    matched_terms.append(term)
                    has_core = True

        # 3. ì¼ë°˜ ìš©ì–´ í™•ì¸ (ì§„ë‹¨ìš©)
        general_matched = []
        for term in self.general_terms:
            term_lower = term.lower() if term.isascii() else term
            if term.isascii():
                pattern = r'\b' + re.escape(term_lower) + r'\b'
                if re.search(pattern, full_text_lower):
                    general_matched.append(term)
            else:
                if term in full_text:
                    general_matched.append(term)

        # ì¼ë°˜ ìš©ì–´ë§Œ ìˆëŠ” ê²½ìš° ì²´í¬
        if general_matched and not has_core and not has_high_spec:
            has_general_only = True

        # ë§¤ì¹­ ì •ë³´ ì—…ë°ì´íŠ¸
        match_info['matched_terms'] = list(set(matched_terms))
        match_info['has_core_term'] = has_core
        match_info['has_high_specificity_term'] = has_high_spec
        match_info['has_general_term_only'] = has_general_only

        # Title, Abstract, Keywords ê°ê° í™•ì¸ (ì •ë³´ìš©)
        if any(term.lower() in title.lower() or term in title for term in matched_terms):
            match_info['title_match'] = True
        if any(term.lower() in abstract.lower() or term in abstract for term in matched_terms):
            match_info['abstract_match'] = True
        if any(term.lower() in keywords_text.lower() or term in keywords_text for term in matched_terms):
            match_info['keywords_match'] = True

        # ìµœì¢… íŒë‹¨: ê³ íŠ¹ì´ë„ ìš©ì–´ê°€ ìˆê±°ë‚˜, í•µì‹¬ ìš©ì–´ê°€ ìˆìœ¼ë©´ ì‹ ì¥ ê´€ë ¨
        is_kidney_related = has_high_spec or has_core

        return is_kidney_related, match_info


def filter_papers():
    """Papers ë°ì´í„°ì…‹ í•„í„°ë§ ë©”ì¸ í•¨ìˆ˜"""

    print("=" * 80)
    print("Papers Dataset Kidney Filtering")
    print("=" * 80)
    print()

    # ìš©ì–´ì§‘ ë¡œë“œ
    print("ğŸ“– Loading terminology...")
    matcher = KidneyTerminologyMatcher(TERMINOLOGY_FILE)
    print()

    # ì¶œë ¥ íŒŒì¼ ì´ˆê¸°í™”
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)

    # í†µê³„ ë³€ìˆ˜
    total_count = 0
    filtered_count = 0
    excluded_count = 0

    # í•„í„°ë§ ì§„í–‰
    print(f"ğŸ” Filtering papers from: {INPUT_FILE.name}")
    print(f"ğŸ“ Output file: {OUTPUT_FILE.name}")
    print()

    with open(INPUT_FILE, 'r', encoding='utf-8') as infile, \
         open(OUTPUT_FILE, 'w', encoding='utf-8') as outfile:

        for line_num, line in enumerate(infile, 1):
            total_count += 1

            # ì§„í–‰ ìƒí™© í‘œì‹œ (100ê°œë§ˆë‹¤)
            if total_count % 100 == 0:
                print(f"Progress: {total_count} / 4,850 papers processed "
                      f"({total_count/4850*100:.1f}%) | "
                      f"Filtered: {filtered_count} ({filtered_count/total_count*100:.1f}%)")

            try:
                paper = json.loads(line.strip())

                # ì‹ ì¥ ê´€ë ¨ ì—¬ë¶€ í™•ì¸
                is_kidney_related, match_info = matcher.check_paper(paper)

                if is_kidney_related:
                    # ë§¤ì¹­ ì •ë³´ ì¶”ê°€
                    paper['_filtering_info'] = match_info

                    # í•„í„°ë§ëœ ë…¼ë¬¸ ì €ì¥
                    outfile.write(json.dumps(paper, ensure_ascii=False) + '\n')
                    filtered_count += 1
                else:
                    excluded_count += 1

            except json.JSONDecodeError as e:
                print(f"âš ï¸  JSON decode error at line {line_num}: {e}")
                continue
            except Exception as e:
                print(f"âš ï¸  Error processing line {line_num}: {e}")
                continue

    print()
    print("=" * 80)
    print("âœ… Filtering Complete!")
    print("=" * 80)
    print(f"Total papers processed: {total_count}")
    print(f"Kidney-related papers: {filtered_count} ({filtered_count/total_count*100:.1f}%)")
    print(f"Excluded papers: {excluded_count} ({excluded_count/total_count*100:.1f}%)")
    print()
    print(f"Output saved to: {OUTPUT_FILE}")
    print("=" * 80)

    return {
        'total': total_count,
        'filtered': filtered_count,
        'excluded': excluded_count
    }


if __name__ == "__main__":
    stats = filter_papers()

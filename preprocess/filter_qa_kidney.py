#!/usr/bin/env python3
"""
QA Dataset Kidney Filtering Script
í•„í„°ë§ ê¸°ì¤€: Papersì™€ ë™ì¼í•œ ê°•í™”ëœ í•„í„°ë§ ë¡œì§ ì‚¬ìš©
íŠ¹ë³„ ì²˜ë¦¬: source_datasetê°€ "ëŒ€í•œì‹ ì¥í•™íšŒ"ì¸ ê²½ìš° ìë™ í¬í•¨
"""

import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Set, Tuple

# íŒŒì¼ ê²½ë¡œ
BASE_DIR = Path(__file__).parent.parent
TERMINOLOGY_FILE = BASE_DIR / "data/preprocess/kidney_terminology.json"
INPUT_FILE = BASE_DIR / "data/preprocess/unified_output/qa_enhanced.jsonl"
OUTPUT_FILE = BASE_DIR / "data/preprocess/kidney_filtered/qa_kidney.jsonl"

class KidneyTerminologyMatcher:
    """ì‹ ì¥ ìš©ì–´ ë§¤ì¹­ í´ë˜ìŠ¤"""

    def __init__(self, terminology_file: Path):
        """ìš©ì–´ì§‘ ë¡œë“œ"""
        with open(terminology_file, 'r', encoding='utf-8') as f:
            self.terminology = json.load(f)

        # í•µì‹¬ ì‹ ì¥ ìš©ì–´ (ë°˜ë“œì‹œ í•˜ë‚˜ëŠ” í¬í•¨ë˜ì–´ì•¼ í•¨)
        self.core_kidney_terms = {
            'kidney', 'kidneys', 'renal', 'nephro', 'nephrology', 'nephrologist',
            'nephron', 'glomerulus', 'glomeruli', 'glomerular',
            'ì‹ ì¥', 'ì½©íŒ¥', 'ì‚¬êµ¬ì²´', 'ì‹ ì¥í•™'
        }

        # ê³ íŠ¹ì´ë„ ì‹ ì¥ ìš©ì–´ (ì´ê²ƒë§Œ ìˆì–´ë„ ì‹ ì¥ ê´€ë ¨ìœ¼ë¡œ íŒë‹¨)
        self.high_specificity_terms = {
            # ì˜ì–´
            'dialysis', 'hemodialysis', 'haemodialysis', 'peritoneal dialysis',
            'nephrotic syndrome', 'nephritic syndrome', 'glomerulonephritis',
            'nephropathy', 'nephritis', 'nephrosis',
            'kidney transplant', 'kidney transplantation', 'renal transplant', 'renal transplantation',
            'acute kidney injury', 'chronic kidney disease', 'end-stage renal disease', 'renal failure',
            'proteinuria', 'albuminuria', 'hematuria',
            'IgA nephropathy', 'membranous nephropathy', 'focal segmental glomerulosclerosis',
            'diabetic nephropathy', 'diabetic kidney disease',
            'polycystic kidney disease', 'kidney stone', 'nephrolithiasis',
            'pyelonephritis', 'interstitial nephritis',
            'renal artery stenosis', 'hydronephrosis',
            'renal cell carcinoma', 'kidney cancer',
            # ì•½ì–´
            'CKD', 'ESRD', 'ESKD', 'AKI', 'ARF', 'FSGS', 'CAPD', 'APD', 'CRRT',
            'PKD', 'ADPKD', 'RCC', 'GFR', 'eGFR',
            # í•œêµ­ì–´
            'íˆ¬ì„', 'í˜ˆì•¡íˆ¬ì„', 'ë³µë§‰íˆ¬ì„', 'ì‹ ì¦í›„êµ°', 'ì‹ ì—¼ì¦í›„êµ°', 'ì‚¬êµ¬ì²´ì‹ ì—¼',
            'ì‹ ë³‘ì¦', 'ì‹ ì—¼', 'ì‹ ì´ì‹', 'ì‹ ì¥ì´ì‹', 'ì½©íŒ¥ì´ì‹',
            'ê¸‰ì„±ì‹ ì†ìƒ', 'ë§Œì„±ì½©íŒ¥ë³‘', 'ë§ê¸°ì‹ ë¶€ì „', 'ì‹ ë¶€ì „',
            'ë‹¨ë°±ë‡¨', 'ì•Œë¶€ë¯¼ë‡¨', 'í˜ˆë‡¨',
            'IgAì‹ ë³‘ì¦', 'ë§‰ì„±ì‹ ë³‘ì¦', 'êµ­ì†Œë¶„ì ˆì‚¬êµ¬ì²´ê²½í™”ì¦',
            'ë‹¹ë‡¨ë³‘ì„±ì‹ ë³‘ì¦', 'ë‹¹ë‡¨ì½©íŒ¥ë³‘',
            'ë‹¤ë‚­ì½©íŒ¥ë³‘', 'ì‹ ê²°ì„', 'ì‹ ìš°ì‹ ì—¼', 'ê°„ì§ˆì‹ ì—¼',
            'ì‹ ë™ë§¥í˜‘ì°©', 'ìˆ˜ì‹ ì¦', 'ì‹ ì„¸í¬ì•”', 'ì½©íŒ¥ì•”'
        }

        # ì‹ ì¥ ê´€ë ¨ source_dataset
        self.kidney_sources = {
            'ëŒ€í•œì‹ ì¥í•™íšŒ'
        }

        # ì‹ ì¥ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ
        self.kidney_category_keywords = {
            'ì½©íŒ¥', 'ì‹ ì¥', 'íˆ¬ì„', 'ì‹ ë¶€ì „', 'ì‹ ì¦í›„êµ°'
        }

        print(f"âœ… Loaded terminology:")
        print(f"   - Core kidney terms: {len(self.core_kidney_terms)}")
        print(f"   - High specificity terms: {len(self.high_specificity_terms)}")
        print(f"   - Kidney sources: {len(self.kidney_sources)}")
        print(f"   - Kidney category keywords: {len(self.kidney_category_keywords)}")

    def check_qa_data(self, data: Dict) -> Tuple[bool, Dict]:
        """
        QA ë°ì´í„°ê°€ ì‹ ì¥ ê´€ë ¨ì¸ì§€ í™•ì¸

        í•„í„°ë§ ê¸°ì¤€:
        1. source_datasetê°€ ëŒ€í•œì‹ ì¥í•™íšŒë©´ ìë™ í¬í•¨
        2. categoryì— ì‹ ì¥ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìë™ í¬í•¨
        3. ê³ íŠ¹ì´ë„ ìš©ì–´ê°€ ìˆìœ¼ë©´ í¬í•¨
        4. í•µì‹¬ ì‹ ì¥ ìš©ì–´ê°€ ìˆìœ¼ë©´ í¬í•¨

        Returns:
            (ì‹ ì¥ ê´€ë ¨ ì—¬ë¶€, ë§¤ì¹­ ì •ë³´ ë”•ì…”ë„ˆë¦¬)
        """
        match_info = {
            'question_match': False,
            'answer_match': False,
            'category_match': False,
            'source_match': False,
            'matched_terms': [],
            'has_core_term': False,
            'has_high_specificity_term': False,
            'auto_included_by_source': False,
            'auto_included_by_category': False
        }

        # 1. Source dataset í™•ì¸
        source_dataset = data.get('source_dataset', '')
        if source_dataset in self.kidney_sources:
            match_info['auto_included_by_source'] = True
            match_info['source_match'] = True
            match_info['matched_terms'].append(f'[source:{source_dataset}]')
            return True, match_info

        # 2. Category í™•ì¸
        category = data.get('category', '')
        for keyword in self.kidney_category_keywords:
            if keyword in category:
                match_info['auto_included_by_category'] = True
                match_info['category_match'] = True
                match_info['matched_terms'].append(f'[category:{keyword}]')
                return True, match_info

        # 3. ì§ˆë¬¸ê³¼ ë‹µë³€ í…ìŠ¤íŠ¸ í™•ì¸
        question = data.get('question', '')
        answer = data.get('answer', '')

        full_text = f"{question} {answer}"
        full_text_lower = full_text.lower()

        # ë§¤ì¹­ëœ ìš©ì–´ ìˆ˜ì§‘
        matched_terms = []
        has_core = False
        has_high_spec = False

        # ê³ íŠ¹ì´ë„ ìš©ì–´ í™•ì¸
        for term in self.high_specificity_terms:
            term_lower = term.lower() if term.isascii() else term
            if term.isascii():
                # ì˜ì–´: ë‹¨ì–´ ê²½ê³„ ê³ ë ¤
                pattern = r'\b' + re.escape(term_lower) + r'\b'
                if re.search(pattern, full_text_lower):
                    matched_terms.append(term)
                    has_high_spec = True
            else:
                # í•œêµ­ì–´: ì •í™•í•œ ë§¤ì¹­
                if term in full_text:
                    matched_terms.append(term)
                    has_high_spec = True

        # í•µì‹¬ ì‹ ì¥ ìš©ì–´ í™•ì¸
        for term in self.core_kidney_terms:
            term_lower = term.lower() if term.isascii() else term
            if term.isascii():
                pattern = r'\b' + re.escape(term_lower) + r'\b'
                if re.search(pattern, full_text_lower):
                    matched_terms.append(term)
                    has_core = True
            else:
                if term in full_text:
                    matched_terms.append(term)
                    has_core = True

        # ë§¤ì¹­ ì •ë³´ ì—…ë°ì´íŠ¸
        match_info['matched_terms'] = list(set(matched_terms))
        match_info['has_core_term'] = has_core
        match_info['has_high_specificity_term'] = has_high_spec

        # Question, Answer ê°ê° í™•ì¸ (ì •ë³´ìš©)
        if any(term.lower() in question.lower() or term in question for term in matched_terms):
            match_info['question_match'] = True
        if any(term.lower() in answer.lower() or term in answer for term in matched_terms):
            match_info['answer_match'] = True

        # ìµœì¢… íŒë‹¨: ê³ íŠ¹ì´ë„ ìš©ì–´ê°€ ìˆê±°ë‚˜, í•µì‹¬ ìš©ì–´ê°€ ìˆìœ¼ë©´ ì‹ ì¥ ê´€ë ¨
        is_kidney_related = has_high_spec or has_core

        return is_kidney_related, match_info


def filter_qa_data():
    """QA ë°ì´í„°ì…‹ í•„í„°ë§ ë©”ì¸ í•¨ìˆ˜"""

    print("=" * 80)
    print("QA Dataset Kidney Filtering")
    print("=" * 80)
    print()

    # ìš©ì–´ì§‘ ë¡œë“œ
    print("ğŸ“– Loading terminology...")
    matcher = KidneyTerminologyMatcher(TERMINOLOGY_FILE)
    print()

    # ì¶œë ¥ íŒŒì¼ ì´ˆê¸°í™”
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)

    # í†µê³„ ë³€ìˆ˜
    total_count = 0
    filtered_count = 0
    excluded_count = 0
    auto_included_by_source = 0
    auto_included_by_category = 0

    # í•„í„°ë§ ì§„í–‰
    print(f"ğŸ” Filtering QA data from: {INPUT_FILE.name}")
    print(f"ğŸ“ Output file: {OUTPUT_FILE.name}")
    print(f"âš ï¸  WARNING: This will process 2,224,451 QA pairs. Expected time: ~10-15 hours")
    print()

    with open(INPUT_FILE, 'r', encoding='utf-8') as infile, \
         open(OUTPUT_FILE, 'w', encoding='utf-8') as outfile:

        for line_num, line in enumerate(infile, 1):
            total_count += 1

            # ì§„í–‰ ìƒí™© í‘œì‹œ (10000ê°œë§ˆë‹¤)
            if total_count % 10000 == 0:
                print(f"Progress: {total_count:,} / 2,224,451 QA pairs processed "
                      f"({total_count/2224451*100:.1f}%) | "
                      f"Filtered: {filtered_count:,} ({filtered_count/total_count*100:.1f}%) | "
                      f"Auto-source: {auto_included_by_source:,} | "
                      f"Auto-category: {auto_included_by_category:,}")

            try:
                data = json.loads(line.strip())

                # ì‹ ì¥ ê´€ë ¨ ì—¬ë¶€ í™•ì¸
                is_kidney_related, match_info = matcher.check_qa_data(data)

                if is_kidney_related:
                    # í†µê³„ ì—…ë°ì´íŠ¸
                    if match_info['auto_included_by_source']:
                        auto_included_by_source += 1
                    if match_info['auto_included_by_category']:
                        auto_included_by_category += 1

                    # ë§¤ì¹­ ì •ë³´ ì¶”ê°€
                    data['_filtering_info'] = match_info

                    # í•„í„°ë§ëœ ë°ì´í„° ì €ì¥
                    outfile.write(json.dumps(data, ensure_ascii=False) + '\n')
                    filtered_count += 1
                else:
                    excluded_count += 1

            except json.JSONDecodeError as e:
                print(f"âš ï¸  JSON decode error at line {line_num}: {e}")
                continue
            except Exception as e:
                print(f"âš ï¸  Error processing line {line_num}: {e}")
                continue

    print()
    print("=" * 80)
    print("âœ… Filtering Complete!")
    print("=" * 80)
    print(f"Total QA pairs processed: {total_count:,}")
    print(f"Kidney-related QA pairs: {filtered_count:,} ({filtered_count/total_count*100:.1f}%)")
    print(f"  - Auto-included by source (ëŒ€í•œì‹ ì¥í•™íšŒ): {auto_included_by_source:,}")
    print(f"  - Auto-included by category: {auto_included_by_category:,}")
    print(f"  - Included by term matching: {filtered_count - auto_included_by_source - auto_included_by_category:,}")
    print(f"Excluded QA pairs: {excluded_count:,} ({excluded_count/total_count*100:.1f}%)")
    print()
    print(f"Output saved to: {OUTPUT_FILE}")
    print("=" * 80)

    return {
        'total': total_count,
        'filtered': filtered_count,
        'excluded': excluded_count,
        'auto_source': auto_included_by_source,
        'auto_category': auto_included_by_category
    }


if __name__ == "__main__":
    stats = filter_qa_data()

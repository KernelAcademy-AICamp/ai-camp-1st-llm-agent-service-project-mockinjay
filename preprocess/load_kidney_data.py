"""
MongoDB ë°ì´í„° ì ì¬ ìŠ¤í¬ë¦½íŠ¸ - ì‹ ì¥(Kidney) ê´€ë ¨ ë°ì´í„°

í•„í„°ë§ëœ JSONL íŒŒì¼ë“¤ì„ MongoDBì˜ ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ì— ì ì¬í•©ë‹ˆë‹¤:
- papers_kidney.jsonl â†’ careguide.papers_kidney
- medical_kidney.jsonl â†’ careguide.medical_kidney
- qa_kidney.jsonl â†’ careguide.qa_kidney
"""

import asyncio
import os
import sys
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "backend"))

from app.db.mongodb_manager import OptimizedMongoDBManager
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


async def load_kidney_data_to_mongodb():
    """í•„í„°ë§ëœ ì‹ ì¥ ë°ì´í„°ë¥¼ MongoDBì— ì ì¬"""

    print("=" * 80)
    print("ğŸ“Š ì‹ ì¥(Kidney) ë°ì´í„° MongoDB ì ì¬ ì‹œì‘")
    print("=" * 80)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # MongoDB Manager ì´ˆê¸°í™” (OptimizedMongoDBManager ì‚¬ìš©)
    mongodb_uri = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
    manager = OptimizedMongoDBManager(uri=mongodb_uri, db_name="careguide")

    try:
        # ì—°ê²° í™•ì¸
        print("ğŸ”Œ MongoDB ì—°ê²° í™•ì¸ ì¤‘...")
        await manager.connect()
        print("âœ… MongoDB ì—°ê²° ì„±ê³µ\n")

        # ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •
        data_dir = project_root / "data" / "preprocess" / "kidney_filtered"

        files_to_load = [
            {
                "file": data_dir / "papers_kidney.jsonl",
                "collection": "papers_kidney",
                "description": "ì—°êµ¬ ë…¼ë¬¸"
            },
            {
                "file": data_dir / "medical_kidney.jsonl",
                "collection": "medical_kidney",
                "description": "ì˜ë£Œ ë¬¸ì„œ"
            },
            {
                "file": data_dir / "qa_kidney.jsonl",
                "collection": "qa_kidney",
                "description": "QA ë°ì´í„°"
            }
        ]

        total_loaded = 0

        # ê° íŒŒì¼ ì ì¬
        for file_info in files_to_load:
            file_path = file_info["file"]
            collection_name = file_info["collection"]
            description = file_info["description"]

            print(f"ğŸ“ [{description}] ì ì¬ ì¤‘...")
            print(f"   íŒŒì¼: {file_path.name}")
            print(f"   ì»¬ë ‰ì…˜: {collection_name}")

            if not file_path.exists():
                print(f"   âš ï¸  ê²½ê³ : íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ - {file_path}")
                print()
                continue

            # íŒŒì¼ í¬ê¸° í™•ì¸
            file_size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"   íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")

            start_time = datetime.now()

            try:
                # JSONL íŒŒì¼ ì½ê¸°
                import json
                from hashlib import md5
                from pymongo import UpdateOne

                data = []
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        data.append(json.loads(line))

                print(f"   ğŸ“– {len(data):,}ê°œ ë¬¸ì„œ ì½ê¸° ì™„ë£Œ")

                # ì»¬ë ‰ì…˜ ì ‘ê·¼
                collection = manager.db[collection_name]

                # ì»¬ë ‰ì…˜ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ upsert ë¡œì§ ì‚¬ìš©
                if "papers" in collection_name:
                    # Papers: DOI ê¸°ë°˜ upsert
                    inserted = 0
                    skipped = 0
                    for paper in data:
                        doi = paper.get("metadata", {}).get("doi")
                        if doi and doi.strip():
                            try:
                                result = await collection.update_one(
                                    {"metadata.doi": doi},
                                    {"$set": paper},
                                    upsert=True
                                )
                                if result.upserted_id:
                                    inserted += 1
                            except Exception:
                                skipped += 1
                        else:
                            skipped += 1
                    loaded_count = inserted
                    if skipped > 0:
                        print(f"   â„¹ï¸  {skipped:,}ê°œ ë¬¸ì„œ ìŠ¤í‚µ (DOI ì—†ìŒ ë˜ëŠ” ì¤‘ë³µ)")

                elif "medical" in collection_name:
                    # Medical: í…ìŠ¤íŠ¸ í•´ì‹œ ê¸°ë°˜ upsert
                    operations = []
                    for med in data:
                        text_hash = md5(med.get("text", "").encode()).hexdigest()
                        med["text_hash"] = text_hash
                        operations.append(
                            UpdateOne(
                                {"text_hash": text_hash},
                                {"$set": med},
                                upsert=True
                            )
                        )

                    if operations:
                        result = await collection.bulk_write(operations)
                        loaded_count = result.upserted_count
                        if result.modified_count > 0:
                            print(f"   â„¹ï¸  {result.modified_count:,}ê°œ ë¬¸ì„œ ì—…ë°ì´íŠ¸ (ì¤‘ë³µ)")
                    else:
                        loaded_count = 0

                elif "qa" in collection_name:
                    # QA: ì§ˆë¬¸ í•´ì‹œ ê¸°ë°˜ upsert
                    operations = []
                    for qa in data:
                        q_hash = md5(qa.get("question", "").encode()).hexdigest()
                        qa["question_hash"] = q_hash
                        operations.append(
                            UpdateOne(
                                {"question_hash": q_hash},
                                {"$set": qa},
                                upsert=True
                            )
                        )

                    if operations:
                        result = await collection.bulk_write(operations)
                        loaded_count = result.upserted_count
                        if result.modified_count > 0:
                            print(f"   â„¹ï¸  {result.modified_count:,}ê°œ ë¬¸ì„œ ì—…ë°ì´íŠ¸ (ì¤‘ë³µ)")
                    else:
                        loaded_count = 0

                else:
                    # ì¼ë°˜ ì‚½ì…
                    result = await collection.insert_many(data, ordered=False)
                    loaded_count = len(result.inserted_ids)

                elapsed = (datetime.now() - start_time).total_seconds()
                total_loaded += loaded_count

                print(f"   âœ… ì„±ê³µ: {loaded_count:,}ê°œ ë¬¸ì„œ ì ì¬")
                print(f"   â±ï¸  ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")

            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()

            print()

        # ìµœì¢… í†µê³„ ì¶œë ¥
        print("=" * 80)
        print("ğŸ“ˆ ì ì¬ ì™„ë£Œ í†µê³„")
        print("=" * 80)

        for file_info in files_to_load:
            collection_name = file_info["collection"]
            description = file_info["description"]

            count = await manager.db[collection_name].count_documents({})
            print(f"âœ“ {description} ({collection_name}): {count:,}ê°œ ë¬¸ì„œ")

        print(f"\nì´ ì ì¬ëœ ë¬¸ì„œ: {total_loaded:,}ê°œ")
        print(f"ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # ì—°ê²° ì¢…ë£Œ
        await manager.close()
        print("\nğŸ”Œ MongoDB ì—°ê²° ì¢…ë£Œ")


if __name__ == "__main__":
    asyncio.run(load_kidney_data_to_mongodb())

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pinecone import Pinecone, ServerlessSpec
from sentence_transformers import SentenceTransformer
from typing import List, Dict
import os
from dotenv import load_dotenv
from database.mongodb_manager import MongoDBManager
import asyncio

load_dotenv()


class VectorDBManager:
    """Pinecone Vector DB ê´€ë¦¬ì - Kidney Medical Embeddings"""

    def __init__(self, index_name: str = "kidney-medical-embeddings"):
        self.index_name = index_name
        self.dimension = 384  # all-MiniLM-L6-v2 ì°¨ì›
        
        # Pinecone ì´ˆê¸°í™”
        api_key = os.getenv("PINECONE_API_KEY")
        if not api_key:
            raise ValueError("PINECONE_API_KEY not found in .env")
        
        self.pc = Pinecone(api_key=api_key)
        self.index = None
        
        # Sentence Transformer ëª¨ë¸
        print("ğŸ“¥ Sentence Transformer ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    
    async def create_index(self):
        """Pinecone ì¸ë±ìŠ¤ ìƒì„± ë˜ëŠ” ì—°ê²°"""
        
        # ì¸ë±ìŠ¤ ì¡´ì¬ í™•ì¸
        existing_indexes = [idx.name for idx in self.pc.list_indexes()]
        
        if self.index_name not in existing_indexes:
            print(f"ğŸ“¦ Pinecone ì¸ë±ìŠ¤ ìƒì„± ì¤‘: {self.index_name}")
            self.pc.create_index(
                name=self.index_name,
                dimension=self.dimension,
                metric="cosine",
                spec=ServerlessSpec(
                    cloud="aws",
                    region="us-east-1"
                )
            )
            print("âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
        else:
            print(f"âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ì—°ê²°: {self.index_name}")
        
        self.index = self.pc.Index(self.index_name)
    
    def generate_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ â†’ ì„ë² ë”© ë²¡í„°"""
        return self.model.encode(text).tolist()
    
    async def upsert_embeddings(
        self,
        docs: List[Dict],
        namespace: str,
        id_field: str = "_id",
        text_fields: List[str] = None
    ):
        """MongoDB ë¬¸ì„œ â†’ Pinecone ì„ë² ë”©
        
        Args:
            docs: MongoDB ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            namespace: Pinecone ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (qa, papers, medical)
            id_field: ë¬¸ì„œ ID í•„ë“œ
            text_fields: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ í•„ë“œ ë¦¬ìŠ¤íŠ¸
        """
        if not docs:
            print("âš ï¸ ì„ë² ë”©í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        vectors = []
        
        for doc in docs:
            # ID ì¶”ì¶œ
            doc_id = str(doc.get(id_field, ""))
            if not doc_id:
                continue
            
            # í…ìŠ¤íŠ¸ ê²°í•©
            if text_fields:
                text_parts = [str(doc.get(field, "")) for field in text_fields]
                combined_text = " ".join(filter(None, text_parts))
            else:
                # ê¸°ë³¸: ëª¨ë“  ë¬¸ìì—´ í•„ë“œ ê²°í•©
                combined_text = " ".join([
                    str(v) for v in doc.values() 
                    if isinstance(v, str) and v
                ])
            
            if not combined_text.strip():
                continue
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.generate_embedding(combined_text)
            
            # ë©”íƒ€ë°ì´í„° í‰íƒ„í™” (Pinecone ì œì•½)
            metadata = self.flatten_metadata(doc)
            
            vectors.append({
                "id": doc_id,
                "values": embedding,
                "metadata": metadata
            })
        
        # ë°°ì¹˜ ì—…ë¡œë“œ (100ê°œì”©)
        batch_size = 100
        for i in range(0, len(vectors), batch_size):
            batch = vectors[i:i+batch_size]
            self.index.upsert(vectors=batch, namespace=namespace)
        
        print(f"âœ… {len(vectors)}ê°œ ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ (namespace: {namespace})")
    
    def flatten_metadata(self, doc: Dict) -> Dict:
        """ë©”íƒ€ë°ì´í„° í‰íƒ„í™” - Abstract í¬í•¨"""
        
        # _idëŠ” ObjectIdì´ë¯€ë¡œ ë¬¸ìì—´ ë³€í™˜
        doc_id = str(doc.get("_id", ""))
        
        flat = {
            "doc_id": doc_id,
            "title": doc.get("title", "")[:500],  # Pinecone ì œí•œ ê³ ë ¤
            "abstract": doc.get("abstract", "")[:1000],  # âœ… Abstract ì¶”ê°€ (1000ì ì œí•œ)
            "source": doc.get("source", ""),
            "question": doc.get("question", "")[:500],
            "answer": doc.get("answer", "")[:1000],
            "text": doc.get("text", "")[:1000],
            "keyword": doc.get("keyword", "")[:200],
        }
        
        # metadata í•˜ìœ„ í•„ë“œ
        if "metadata" in doc and isinstance(doc["metadata"], dict):
            metadata = doc["metadata"]
            flat["doi"] = metadata.get("doi", "")
            flat["pmid"] = str(metadata.get("pmid", ""))
            flat["journal"] = metadata.get("journal", "")[:200]
            flat["publication_date"] = metadata.get("publication_date", "")
            
            # ë°°ì—´ í•„ë“œ â†’ ë¬¸ìì—´ ë³€í™˜
            if "keywords" in metadata:
                keywords = metadata["keywords"]
                if isinstance(keywords, list):
                    flat["keywords"] = ", ".join(keywords[:5])  # ìµœëŒ€ 5ê°œ
            
            if "authors" in metadata:
                authors = metadata["authors"]
                if isinstance(authors, list):
                    flat["authors"] = ", ".join(authors[:3])  # ìµœëŒ€ 3ëª…
        
        # None ê°’ ì œê±° (Pinecone ìš”êµ¬ì‚¬í•­)
        return {k: v for k, v in flat.items() if v}
    
    async def semantic_search(
        self,
        query: str,
        top_k: int = 10,
        namespace: str = "papers"
    ) -> List[Dict]:
        """ì˜ë¯¸ë¡ ì  ê²€ìƒ‰
        
        Returns:
            [
                {
                    "id": "doc_id",
                    "score": 0.85,
                    "metadata": {...}
                },
                ...
            ]
        """
        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.generate_embedding(query)
        
        # Pinecone ê²€ìƒ‰
        results = self.index.query(
            vector=query_embedding,
            top_k=top_k,
            namespace=namespace,
            include_metadata=True
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        matches = []
        for match in results.matches:
            matches.append({
                "id": match.id,
                "score": match.score,
                "metadata": match.metadata
            })
        
        return matches


# ==================== MongoDB â†’ Pinecone ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ====================

async def embed_all_data():
    """ëª¨ë“  MongoDB ë°ì´í„°ë¥¼ Pineconeì— ì„ë² ë”©"""
    
    mongo = MongoDBManager()
    await mongo.connect()
    
    vector_db = VectorDBManager()
    await vector_db.create_index()
    
    # 1. QA ë°ì´í„° ì„ë² ë”©
    print("\nğŸ“ QA ë°ì´í„° ì„ë² ë”© ì¤‘...")
    qa_cursor = mongo.db.qa_data.find({})
    qa_docs = await qa_cursor.to_list(length=1000)
    
    if qa_docs:
        await vector_db.upsert_embeddings(
            docs=qa_docs,
            namespace="qa",
            text_fields=["question", "answer"]
        )
    
    # 2. ë…¼ë¬¸ ë°ì´í„° ì„ë² ë”© (Abstract í¬í•¨)
    print("\nğŸ“„ ë…¼ë¬¸ ë°ì´í„° ì„ë² ë”© ì¤‘...")
    paper_cursor = mongo.db.papers.find({})
    paper_docs = await paper_cursor.to_list(length=1000)
    
    if paper_docs:
        await vector_db.upsert_embeddings(
            docs=paper_docs,
            namespace="papers",
            text_fields=["title", "abstract"]  # âœ… Abstract í¬í•¨
        )
    
    # 3. ì˜ë£Œ ë°ì´í„° ì„ë² ë”©
    print("\nğŸ¥ ì˜ë£Œ ë°ì´í„° ì„ë² ë”© ì¤‘...")
    medical_cursor = mongo.db.medical_data.find({})
    medical_docs = await medical_cursor.to_list(length=1000)
    
    if medical_docs:
        await vector_db.upsert_embeddings(
            docs=medical_docs,
            namespace="medical",
            text_fields=["text", "keyword"]
        )
    
    await mongo.close()
    print("\nâœ… ëª¨ë“  ë°ì´í„° ì„ë² ë”© ì™„ë£Œ!")


# ==================== í…ŒìŠ¤íŠ¸ ====================

async def test_semantic_search():
    """ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    
    vector_db = VectorDBManager()
    await vector_db.create_index()
    
    query = "chronic kidney disease treatment"
    
    print(f"\nğŸ” ì˜ë¯¸ë¡ ì  ê²€ìƒ‰: '{query}'")
    
    # ë…¼ë¬¸ ê²€ìƒ‰
    print("\n--- ë…¼ë¬¸ ê²°ê³¼ ---")
    paper_results = await vector_db.semantic_search(query, top_k=3, namespace="papers")
    
    for i, result in enumerate(paper_results, 1):
        print(f"\n{i}. Score: {result['score']:.3f}")
        print(f"   Title: {result['metadata'].get('title', 'N/A')}")
        print(f"   Abstract: {result['metadata'].get('abstract', 'N/A')[:200]}...")  # âœ… Abstract ì¶œë ¥
        print(f"   DOI: {result['metadata'].get('doi', 'N/A')}")


if __name__ == "__main__":
    import asyncio
    
    # ì „ì²´ ì„ë² ë”© ì‹¤í–‰
    asyncio.run(embed_all_data())
    
    # í…ŒìŠ¤íŠ¸
    # asyncio.run(test_semantic_search())

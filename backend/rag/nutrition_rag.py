"""
Nutrition RAG - CLIP + Pinecone Hybrid Search
ìŒì‹ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë™ì‹œ ê²€ìƒ‰ì„ ìœ„í•œ RAG ì‹œìŠ¤í…œ
"""

import os
import logging
from typing import List, Dict, Any, Optional, Union
from io import BytesIO
import base64

import torch
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
from pinecone import Pinecone, ServerlessSpec
from rank_bm25 import BM25Okapi

logger = logging.getLogger(__name__)


class NutritionRAG:
    """CLIP ê¸°ë°˜ ìŒì‹ ê²€ìƒ‰ RAG - ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""

    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # CLIP ëª¨ë¸ ì´ˆê¸°í™”
        logger.info(f"ğŸ”§ Loading CLIP model on {self.device}")
        self.model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
        self.processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
        self.model.to(self.device)
        self.model.eval()

        # Pinecone ì´ˆê¸°í™”
        self.pc = None
        self.index = None
        self._init_pinecone()

        # BM25 for keyword search (in-memory cache)
        self.bm25 = None
        self.food_corpus = []

    def _init_pinecone(self):
        """Pinecone vector DB ì´ˆê¸°í™”"""
        api_key = os.getenv("PINECONE_API_KEY")
        if not api_key:
            logger.warning("âš ï¸ PINECONE_API_KEY not found - RAG disabled")
            return

        try:
            self.pc = Pinecone(api_key=api_key)
            index_name = "nutrition-ckd"

            # Check if index exists
            existing_indexes = self.pc.list_indexes()
            if index_name not in [idx.name for idx in existing_indexes]:
                logger.info(f"ğŸ“¦ Creating Pinecone index: {index_name}")
                self.pc.create_index(
                    name=index_name,
                    dimension=512,  # CLIP embedding dimension
                    metric="cosine",
                    spec=ServerlessSpec(cloud="aws", region="us-east-1")
                )

            self.index = self.pc.Index(index_name)
            logger.info(f"âœ… Pinecone index '{index_name}' ready")

        except Exception as e:
            logger.error(f"âŒ Pinecone initialization failed: {e}")
            self.pc = None
            self.index = None

    def _unflatten_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """
        Pinecone ë©”íƒ€ë°ì´í„°ì—ì„œ nutrition í•„ë“œë¥¼ ë³µì›

        Args:
            metadata: Flattened metadata from Pinecone

        Returns:
            Unflattened metadata with nutrition dict
        """
        nutrition = {}
        result = {}

        for key, value in metadata.items():
            if key.startswith("nutrition_"):
                # Extract nutrition field
                field_name = key.replace("nutrition_", "")
                nutrition[field_name] = value
            else:
                result[key] = value

        if nutrition:
            result["nutrition"] = nutrition

        return result

    def encode_image(self, image_input: Union[str, Image.Image]) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ë¥¼ CLIP ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜

        Args:
            image_input: PIL Image ë˜ëŠ” base64 string

        Returns:
            CLIP image embedding (512-dim)
        """
        try:
            # Base64 string to PIL Image
            if isinstance(image_input, str):
                image_bytes = base64.b64decode(image_input)
                image = Image.open(BytesIO(image_bytes)).convert("RGB")
            else:
                image = image_input

            # CLIP preprocessing
            inputs = self.processor(images=image, return_tensors="pt")
            inputs = {k: v.to(self.device) for k, v in inputs.items()}

            with torch.no_grad():
                image_features = self.model.get_image_features(**inputs)
                # Normalize
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)

            return image_features.cpu().squeeze()

        except Exception as e:
            logger.error(f"Image encoding failed: {e}")
            raise

    def encode_text(self, text: str) -> torch.Tensor:
        """
        í…ìŠ¤íŠ¸ë¥¼ CLIP ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜

        Args:
            text: ê²€ìƒ‰ ì¿¼ë¦¬ í…ìŠ¤íŠ¸

        Returns:
            CLIP text embedding (512-dim)
        """
        try:
            # Truncate text to fit CLIP's 77 token limit (~200 chars for Korean)
            if len(text) > 200:
                text = text[:200]

            inputs = self.processor(text=[text], return_tensors="pt", padding=True, truncation=True, max_length=77)
            inputs = {k: v.to(self.device) for k, v in inputs.items()}

            with torch.no_grad():
                text_features = self.model.get_text_features(**inputs)
                # Normalize
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)

            return text_features.cpu().squeeze()

        except Exception as e:
            logger.error(f"Text encoding failed: {e}")
            raise

    def search_by_image(
        self,
        image_input: Union[str, Image.Image],
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ì´ë¯¸ì§€ë¡œ ìœ ì‚¬ ìŒì‹ ê²€ìƒ‰

        Args:
            image_input: ìŒì‹ ì´ë¯¸ì§€ (PIL ë˜ëŠ” base64)
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜

        Returns:
            List of {dish_name, ingredients, recipe, nutrition, score}
        """
        if not self.index:
            logger.warning("Pinecone not available - using dummy data")
            return self._get_dummy_food_data(top_k)

        try:
            # Image embedding
            image_emb = self.encode_image(image_input)

            # Pinecone search
            results = self.index.query(
                vector=image_emb.tolist(),
                top_k=top_k,
                include_metadata=True
            )

            foods = []
            for match in results.matches:
                unflattened = self._unflatten_metadata(match.metadata)
                foods.append({
                    "dish_name": unflattened.get("dish_name", "Unknown"),
                    "ingredients": unflattened.get("ingredients", []),
                    "recipe": unflattened.get("recipe", ""),
                    "nutrition": unflattened.get("nutrition", {}),
                    "score": match.score
                })

            return foods

        except Exception as e:
            logger.error(f"Image search failed: {e}")
            return self._get_dummy_food_data(top_k)

    def search_by_text(
        self,
        query: str,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ë¡œ ìŒì‹ ê²€ìƒ‰ (ì‹œë§¨í‹± ê²€ìƒ‰)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (ìŒì‹ëª…, ì‹ì¬ë£Œ ë“±)
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜

        Returns:
            List of {dish_name, ingredients, recipe, nutrition, score}
        """
        if not self.index:
            logger.warning("Pinecone not available - using dummy data")
            return self._get_dummy_food_data(top_k)

        try:
            # Text embedding
            text_emb = self.encode_text(query)

            # Pinecone search
            results = self.index.query(
                vector=text_emb.tolist(),
                top_k=top_k,
                include_metadata=True
            )

            foods = []
            for match in results.matches:
                unflattened = self._unflatten_metadata(match.metadata)
                foods.append({
                    "dish_name": unflattened.get("dish_name", "Unknown"),
                    "ingredients": unflattened.get("ingredients", []),
                    "recipe": unflattened.get("recipe", ""),
                    "nutrition": unflattened.get("nutrition", {}),
                    "score": match.score
                })

            return foods

        except Exception as e:
            logger.error(f"Text search failed: {e}")
            return self._get_dummy_food_data(top_k)

    def hybrid_search(
        self,
        query: str,
        top_k: int = 5,
        semantic_weight: float = 0.7
    ) -> List[Dict[str, Any]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ì‹œë§¨í‹± + BM25 í‚¤ì›Œë“œ)

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜
            semantic_weight: ì‹œë§¨í‹± ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (0~1)

        Returns:
            List of {dish_name, ingredients, recipe, nutrition, score}
        """
        # Semantic search
        semantic_results = self.search_by_text(query, top_k=top_k * 2)

        # BM25 keyword search (if corpus loaded)
        if self.bm25 and self.food_corpus:
            tokenized_query = query.split()
            bm25_scores = self.bm25.get_scores(tokenized_query)

            # Combine scores
            combined = {}
            for idx, food in enumerate(self.food_corpus):
                dish_name = food["dish_name"]
                # Normalize BM25 scores
                bm25_score = bm25_scores[idx] / (max(bm25_scores) + 1e-6)

                # Find semantic score
                semantic_score = 0
                for sem_result in semantic_results:
                    if sem_result["dish_name"] == dish_name:
                        semantic_score = sem_result["score"]
                        break

                # Weighted combination
                combined[dish_name] = {
                    **food,
                    "score": semantic_weight * semantic_score + (1 - semantic_weight) * bm25_score
                }

            # Sort by combined score
            ranked = sorted(combined.values(), key=lambda x: x["score"], reverse=True)
            return ranked[:top_k]

        else:
            # Fallback to semantic only
            return semantic_results[:top_k]

    def load_food_corpus(self, foods: List[Dict[str, Any]]):
        """
        BM25ë¥¼ ìœ„í•œ ìŒì‹ ì½”í¼ìŠ¤ ë¡œë“œ

        Args:
            foods: List of {dish_name, ingredients, recipe, nutrition}
        """
        self.food_corpus = foods

        # Tokenize for BM25
        corpus_texts = [
            f"{food['dish_name']} {' '.join(food.get('ingredients', []))} {food.get('recipe', '')}"
            for food in foods
        ]
        tokenized_corpus = [doc.split() for doc in corpus_texts]

        self.bm25 = BM25Okapi(tokenized_corpus)
        logger.info(f"ğŸ“š BM25 corpus loaded: {len(foods)} foods")

    def upsert_food(
        self,
        food_id: str,
        dish_name: str,
        ingredients: List[str],
        recipe: str,
        nutrition: Dict[str, Any],
        image: Optional[Image.Image] = None
    ):
        """
        ìŒì‹ ë°ì´í„°ë¥¼ Pineconeì— ì¶”ê°€

        Args:
            food_id: Unique ID
            dish_name: ìš”ë¦¬ëª…
            ingredients: ì‹ì¬ë£Œ ë¦¬ìŠ¤íŠ¸
            recipe: ì¡°ë¦¬ë²•
            nutrition: ì˜ì–‘ ì •ë³´ {sodium, potassium, phosphorus, protein, calcium}
            image: ìŒì‹ ì´ë¯¸ì§€ (ì„ íƒ)
        """
        if not self.index:
            logger.warning("Pinecone not available - skipping upsert")
            return

        try:
            # Generate embedding (image or text)
            if image:
                embedding = self.encode_image(image)
            else:
                # Fallback to text embedding
                text = f"{dish_name} {' '.join(ingredients)} {recipe}"
                embedding = self.encode_text(text)

            # Flatten nutrition metadata (Pinecone doesn't support nested dicts)
            metadata = {
                "dish_name": dish_name,
                "ingredients": ingredients,
                "recipe": recipe[:500] if recipe else "",  # Truncate long recipes
            }

            # Add flattened nutrition fields
            if nutrition:
                for key, value in nutrition.items():
                    metadata[f"nutrition_{key}"] = float(value) if value else 0.0

            # Upsert to Pinecone
            self.index.upsert(
                vectors=[(
                    food_id,
                    embedding.tolist(),
                    metadata
                )]
            )

            logger.info(f"âœ… Upserted food: {dish_name} (ID: {food_id})")

        except Exception as e:
            logger.error(f"Upsert failed for {dish_name}: {e}")

    def _get_dummy_food_data(self, top_k: int = 5) -> List[Dict[str, Any]]:
        """ë”ë¯¸ ìŒì‹ ë°ì´í„° (RAG ë¹„í™œì„±í™” ì‹œ)"""
        dummy_foods = [
            {
                "dish_name": "ì €ì—¼ ë‹­ê°€ìŠ´ì‚´ ìƒëŸ¬ë“œ",
                "ingredients": ["ë‹­ê°€ìŠ´ì‚´", "ì–‘ë°°ì¶”", "ì˜¤ì´", "ë°©ìš¸í† ë§ˆí† ", "ì˜¬ë¦¬ë¸Œì˜¤ì¼"],
                "recipe": "ë‹­ê°€ìŠ´ì‚´ì„ ì‚¶ì•„ ì°¢ê³ , ë°ì¹œ ì•¼ì±„ì™€ í•¨ê»˜ ì˜¬ë¦¬ë¸Œì˜¤ì¼ ë“œë ˆì‹±ìœ¼ë¡œ ë²„ë¬´ë¦½ë‹ˆë‹¤.",
                "nutrition": {
                    "sodium": 350,
                    "potassium": 450,
                    "phosphorus": 180,
                    "protein": 28,
                    "calcium": 65
                },
                "score": 0.95
            },
            {
                "dish_name": "ì €ì¸ ê³„ë€ ë³¶ìŒë°¥",
                "ingredients": ["í˜„ë¯¸ë°¥", "ê³„ë€ í°ì", "ì–‘íŒŒ", "ë‹¹ê·¼", "ì €ì—¼ ê°„ì¥"],
                "recipe": "í˜„ë¯¸ë°¥ì— ê³„ë€ í°ìì™€ ì•¼ì±„ë¥¼ ë„£ê³  ì €ì—¼ ê°„ì¥ìœ¼ë¡œ ê°„í•˜ì—¬ ë³¶ìŠµë‹ˆë‹¤.",
                "nutrition": {
                    "sodium": 420,
                    "potassium": 380,
                    "phosphorus": 220,
                    "protein": 18,
                    "calcium": 45
                },
                "score": 0.88
            },
            {
                "dish_name": "ì €ì¹¼ë¥¨ ì•¼ì±„ ìŠ¤í”„",
                "ingredients": ["ì–‘ë°°ì¶”", "ê°€ì§€", "ì• í˜¸ë°•", "ë‹¹ê·¼", "í—ˆë¸Œ"],
                "recipe": "ì•¼ì±„ë¥¼ ë°ì³ ì¹¼ë¥¨ì„ ì œê±°í•œ í›„ í—ˆë¸Œë¡œ ê°„ì„ í•˜ì—¬ ë“ì…ë‹ˆë‹¤.",
                "nutrition": {
                    "sodium": 280,
                    "potassium": 320,
                    "phosphorus": 95,
                    "protein": 8,
                    "calcium": 72
                },
                "score": 0.82
            }
        ]

        return dummy_foods[:top_k]

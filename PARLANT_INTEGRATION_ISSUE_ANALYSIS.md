# Parlant Integration Issue Analysis and Solution

## Problem Summary

When a user sends a research query like "Ïã†Ïû• Í¥ÄÎ†® ÏµúÏã† Ïó∞Íµ¨ ÎÖºÎ¨∏ ÏïåÎ†§Ï§ò":
1. RouterAgent correctly classifies intent as RESEARCH and routes to research_paper
2. Parlant server receives the request and successfully calls `search_medical_qa` tool (returns 20 results in ~5.7s)
3. Parlant makes OpenAI API calls successfully (3 calls shown in logs)
4. BUT the backend keeps getting `504 Gateway Timeout` when polling for events after offset 4
5. The preamble message is received (offset 3), but the actual response never arrives

## Root Cause Analysis

After investigating the Parlant SDK documentation and examining the code, I've identified **THREE KEY ISSUES**:

### Issue 1: Response Not Being Generated by Parlant

The logs show:
- Tool execution completes successfully (20 results, ~5.7s)
- OpenAI API calls are made (3 times)
- Preamble message is sent (offset 3)
- BUT no actual agent response message follows

**Diagnosis**: The Parlant server is likely NOT generating the final agent response message after the tool execution. This could be because:
1. The `refinement_prompt` returned by the tool is too large (could exceed token limits)
2. The agent is waiting for additional processing
3. There's an error in the agent's response generation that's not being logged

### Issue 2: Event Source Filter Too Narrow

In `agent.py` line 284, the code filters events:
```python
new_agent_messages = [
    event for event in events
    if event.kind == 'message' and event.source in ('agent', 'ai_agent')
]
```

According to Parlant SDK signature, valid sources are:
- `'customer'`
- `'customer_ui'`
- `'human_agent'`
- `'human_agent_on_behalf_of_ai_agent'`
- **`'ai_agent'`** ‚Üê This is correct
- `'system'`

**The problem**: The code checks for source `'agent'`, but that's NOT a valid Parlant source type! Only `'ai_agent'` is valid for automated agent responses.

### Issue 3: Inefficient Polling Strategy

The current implementation:
```python
wait_for_data=3  # Only 3 seconds
```

This is too short. Based on Parlant documentation and examples:
- Recommended `wait_for_data` is **30-60 seconds** for long polling
- This prevents constant rapid requests and allows the server time to generate responses
- The current 3-second timeout causes unnecessary network overhead

### Issue 4: Missing Event Data Structure Handling

The code accesses event data incorrectly in some places:
```python
event_data = msg.data if hasattr(msg, 'data') else {}
tags = event_data.get('tags', []) if isinstance(event_data, dict) else []
message_text = event_data.get('message', '') if isinstance(event_data, dict) else ''
```

According to Parlant Event structure, events have:
- `offset`: int
- `kind`: str
- `source`: str
- `data`: dict (contains the actual message content)

The data structure for message events typically includes:
- `data.message`: The actual message text
- `data.tags`: List of tags (including `'__preamble__'` for preamble messages)

## Solution

### Fix 1: Remove Invalid 'agent' Source Filter

**File**: `/Users/apple/Coding/ai-camp-1st-llm-agent-service-project-mockinjay/backend/Agent/research_paper/agent.py`

**Lines to Fix**:
- Line 284 (in `process_stream`)
- Line 466 (in `process`)

**Change**:
```python
# BEFORE (WRONG):
new_agent_messages = [
    event for event in events
    if event.kind == 'message' and event.source in ('agent', 'ai_agent')
]

# AFTER (CORRECT):
new_agent_messages = [
    event for event in events
    if event.kind == 'message' and event.source == 'ai_agent'
]
```

### Fix 2: Increase wait_for_data Timeout

**Lines to Fix**:
- Line 279 (in `process_stream`): Change `wait_for_data=3` ‚Üí `wait_for_data=30`
- Line 459 (in `process`): Change `wait_for_data=5` ‚Üí `wait_for_data=30`

**Reasoning**:
- Parlant documentation recommends 30-60 seconds for long polling
- This matches the pattern used in Parlant's own examples
- Gives the LLM enough time to generate responses (especially for large tool results)

### Fix 3: Improve Error Handling and Logging

Add more detailed logging to understand what events are being received:

```python
# Log all events received, not just agent messages
for event in events:
    logger.info(f"üì© Event received: offset={event.offset}, kind={event.kind}, source={event.source}")
    if hasattr(event, 'data'):
        logger.info(f"   Data keys: {list(event.data.keys()) if isinstance(event.data, dict) else 'not dict'}")
```

### Fix 4: Verify Tool Result Size

The `search_medical_qa` tool returns a `refinement_prompt` that contains all search results in toon_format. This could be very large.

**Check**: In `healthcare_v2_en.py` line 591, add logging:
```python
result_size_bytes = len(result_json)
if result_size_bytes > 100 * 1024:  # 100KB
    logger.warning(f"‚ö†Ô∏è Large tool result: {result_size_bytes / 1024:.1f} KB - may cause LLM delays")
```

### Fix 5: Handle Long Response Generation Time

The OpenAI API calls shown in logs (3 calls) suggest the LLM is processing, but responses may take longer than expected.

**Solution**: Increase the total wait time and polling patience:

```python
# In process_stream (line 259):
max_wait_time = 300  # Increase from 600 to 300 seconds (5 minutes is reasonable)
poll_interval = 30   # Match wait_for_data
max_no_new_events = 10  # 10 polls √ó 30s = 5 minutes max idle time

# In process (line 437):
max_wait_time = 300  # Same
poll_interval = 30   # Same
max_no_new_events = 10  # Same
```

## Testing Plan

1. **Apply fixes** to `agent.py`
2. **Restart both servers**:
   - Parlant server (healthcare_v2_en.py)
   - FastAPI backend
3. **Test with research query**: "Ïã†Ïû• Í¥ÄÎ†® ÏµúÏã† Ïó∞Íµ¨ ÎÖºÎ¨∏ ÏïåÎ†§Ï§ò"
4. **Monitor logs** for:
   - All events received (not just agent messages)
   - Event data structure
   - Response generation time
   - Any errors or warnings

## Expected Behavior After Fix

1. Customer message sent (offset 0)
2. Preamble message received (offset 1-3, tagged with `__preamble__`)
3. Tool execution starts (visible in Parlant server logs)
4. Tool completes successfully (20 results, ~5.7s)
5. OpenAI API calls for response generation (may take 30-60 seconds)
6. **Agent response message arrives** (offset 4+, source='ai_agent', contains answer)
7. Response streamed to client

## Additional Recommendations

1. **Add Circuit Breaker**: If Parlant server consistently fails, fail fast instead of retrying forever
2. **Add Metrics**: Track response times, timeout rates, and success rates
3. **Consider SSE**: For better real-time streaming, consider using Server-Sent Events instead of polling
4. **Tool Result Optimization**: Consider compressing or truncating the `refinement_prompt` if it's too large

## References

- [Parlant Custom Frontend Docs](https://www.parlant.io/docs/production/custom-frontend/)
- [Parlant Sessions Documentation](https://www.parlant.io/docs/concepts/customization/sessions/)
- Parlant SDK Source: `parlant.client.sessions.client.AsyncSessionsClient.list_events`

## Files Modified

1. `/Users/apple/Coding/ai-camp-1st-llm-agent-service-project-mockinjay/backend/Agent/research_paper/agent.py`
   - Line 284: Fix source filter in `process_stream`
   - Line 279: Increase wait_for_data to 30
   - Line 259-266: Adjust timeout parameters
   - Line 466: Fix source filter in `process`
   - Line 459: Increase wait_for_data to 30
   - Line 437-444: Adjust timeout parameters
   - Add detailed event logging

---

**Created**: 2025-11-27
**Status**: Ready for implementation
